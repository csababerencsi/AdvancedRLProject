{
    "name": "root",
    "gauges": {
        "PelletSearch.Policy.Entropy.mean": {
            "value": 1.4044705629348755,
            "min": 1.4044705629348755,
            "max": 1.4226274490356445,
            "count": 102
        },
        "PelletSearch.Policy.Entropy.sum": {
            "value": 7027.970703125,
            "min": 6476.7314453125,
            "max": 8952.0830078125,
            "count": 102
        },
        "PelletSearch.Environment.EpisodeLength.mean": {
            "value": 11.495,
            "min": 10.76865671641791,
            "max": 808.9090909090909,
            "count": 102
        },
        "PelletSearch.Environment.EpisodeLength.sum": {
            "value": 4598.0,
            "min": 2265.0,
            "max": 8898.0,
            "count": 102
        },
        "PelletSearch.Step.mean": {
            "value": 509995.0,
            "min": 4835.0,
            "max": 509995.0,
            "count": 102
        },
        "PelletSearch.Step.sum": {
            "value": 509995.0,
            "min": 4835.0,
            "max": 509995.0,
            "count": 102
        },
        "PelletSearch.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.5461873412132263,
            "min": -0.24567247927188873,
            "max": 0.569889485836029,
            "count": 102
        },
        "PelletSearch.Policy.ExtrinsicValueEstimate.sum": {
            "value": 218.47494506835938,
            "min": -6.387484550476074,
            "max": 230.81448364257812,
            "count": 102
        },
        "PelletSearch.Environment.CumulativeReward.mean": {
            "value": 0.955,
            "min": -1.0,
            "max": 0.9772727272727273,
            "count": 102
        },
        "PelletSearch.Environment.CumulativeReward.sum": {
            "value": 382.0,
            "min": -13.0,
            "max": 401.0,
            "count": 102
        },
        "PelletSearch.Policy.ExtrinsicReward.mean": {
            "value": 0.955,
            "min": -1.0,
            "max": 0.9772727272727273,
            "count": 102
        },
        "PelletSearch.Policy.ExtrinsicReward.sum": {
            "value": 382.0,
            "min": -13.0,
            "max": 401.0,
            "count": 102
        },
        "PelletSearch.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 102
        },
        "PelletSearch.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 102
        },
        "PelletSearch.Losses.PolicyLoss.mean": {
            "value": 0.019756117145772332,
            "min": 0.015396039639772088,
            "max": 0.028384655645048176,
            "count": 50
        },
        "PelletSearch.Losses.PolicyLoss.sum": {
            "value": 0.019756117145772332,
            "min": 0.015396039639772088,
            "max": 0.028384655645048176,
            "count": 50
        },
        "PelletSearch.Losses.ValueLoss.mean": {
            "value": 0.04220191886027654,
            "min": 0.0044236315362569355,
            "max": 0.05808351437250773,
            "count": 50
        },
        "PelletSearch.Losses.ValueLoss.sum": {
            "value": 0.04220191886027654,
            "min": 0.0044236315362569355,
            "max": 0.05808351437250773,
            "count": 50
        },
        "PelletSearch.Policy.LearningRate.mean": {
            "value": 4.9759050241000016e-05,
            "min": 4.9759050241000016e-05,
            "max": 9.897880102119999e-05,
            "count": 50
        },
        "PelletSearch.Policy.LearningRate.sum": {
            "value": 4.9759050241000016e-05,
            "min": 4.9759050241000016e-05,
            "max": 9.897880102119999e-05,
            "count": 50
        },
        "PelletSearch.Policy.Epsilon.mean": {
            "value": 0.14975900000000003,
            "min": 0.14975900000000003,
            "max": 0.1989788,
            "count": 50
        },
        "PelletSearch.Policy.Epsilon.sum": {
            "value": 0.14975900000000003,
            "min": 0.14975900000000003,
            "max": 0.1989788,
            "count": 50
        },
        "PelletSearch.Policy.Beta.mean": {
            "value": 0.0024929741000000007,
            "min": 0.0024929741000000007,
            "max": 0.00494904212,
            "count": 50
        },
        "PelletSearch.Policy.Beta.sum": {
            "value": 0.0024929741000000007,
            "min": 0.0024929741000000007,
            "max": 0.00494904212,
            "count": 50
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1713191945",
        "python_version": "3.9.11 (tags/v3.9.11:2de452f, Mar 16 2022, 14:33:45) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "D:\\Unity Projects\\MLAgents_Intro\\venv\\Scripts\\mlagents-learn .\\PelletSearch.yaml --run-id=PelletGrab07",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.2.2+cu121",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1713192738"
    },
    "total": 792.861309,
    "count": 1,
    "self": 0.0075496000000612185,
    "children": {
        "run_training.setup": {
            "total": 0.11718649999999986,
            "count": 1,
            "self": 0.11718649999999986
        },
        "TrainerController.start_learning": {
            "total": 792.7365728999999,
            "count": 1,
            "self": 1.5815908000107584,
            "children": {
                "TrainerController._reset_env": {
                    "total": 7.7557735999999995,
                    "count": 1,
                    "self": 7.7557735999999995
                },
                "TrainerController.advance": {
                    "total": 783.2956714999892,
                    "count": 71746,
                    "self": 1.5196914999651199,
                    "children": {
                        "env_step": {
                            "total": 601.8788291000119,
                            "count": 71746,
                            "self": 462.88296779999325,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 138.01913990001304,
                                    "count": 71746,
                                    "self": 4.107499499996095,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 133.91164040001695,
                                            "count": 56980,
                                            "self": 133.91164040001695
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.9767214000055962,
                                    "count": 71745,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 783.9268382000065,
                                            "count": 71745,
                                            "is_parallel": true,
                                            "self": 403.40154910000314,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.00027810000000005886,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 9.639999999944138e-05,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00018170000000061748,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.00018170000000061748
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 380.52501100000336,
                                                    "count": 71745,
                                                    "is_parallel": true,
                                                    "self": 8.182435499995506,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 10.38503489999276,
                                                            "count": 71745,
                                                            "is_parallel": true,
                                                            "self": 10.38503489999276
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 344.1298958000013,
                                                            "count": 71745,
                                                            "is_parallel": true,
                                                            "self": 344.1298958000013
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 17.82764480001379,
                                                            "count": 71745,
                                                            "is_parallel": true,
                                                            "self": 7.815971999987271,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 10.011672800026519,
                                                                    "count": 143490,
                                                                    "is_parallel": true,
                                                                    "self": 10.011672800026519
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 179.8971509000122,
                            "count": 71745,
                            "self": 1.8712472000104299,
                            "children": {
                                "process_trajectory": {
                                    "total": 81.23814540000184,
                                    "count": 71745,
                                    "self": 81.12193640000181,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.11620900000002621,
                                            "count": 1,
                                            "self": 0.11620900000002621
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 96.78775829999992,
                                    "count": 51,
                                    "self": 74.0952263000003,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 22.692531999999613,
                                            "count": 1377,
                                            "self": 22.692531999999613
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.7999999499807018e-06,
                    "count": 1,
                    "self": 1.7999999499807018e-06
                },
                "TrainerController._save_models": {
                    "total": 0.10353520000001026,
                    "count": 1,
                    "self": 0.026608699999997043,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.07692650000001322,
                            "count": 1,
                            "self": 0.07692650000001322
                        }
                    }
                }
            }
        }
    }
}